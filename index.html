<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sankarshana V</title>
  
  <meta name="author" content="Sankarshana V">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/ucla.webp" type="image/x-icon" / >
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sankarshana V</name>
              </p>
              <p>I am Sankarshana V from India, and I am a Master's student at <a href="https://yonsei.ac.kr/">Yonsei University</a>. I received my Bachelor's degree from the <a href="https://ai.yonsei.ac.kr/">Artificial Intelligence Department</a> from Yonsei University</a>. My research focuses on parameter-efficient-tuning with Large Language Models (LLMs) in different domains, spanning from Natural Language Processing (NLP), Speech, and Computer Vision (CV).
              </p>
              <p>
                At Yonsei University, I was fortunate to work with <a href="https://ppolon.github.io/">Prof. Jonghyun Choi</a> on Neuromorphic Cameras and Stereo-Depth Estimation.
              </p>
              <p style="text-align:center">
                <a href="mailto:sankarshana.v@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Sankarshana_s_ResumÃ©.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="https://scholar.google.com.tw/citations?user=qu5wSaQAAAAJ&hl=zh-TW">Google Scholar</a> &nbsp/&nbsp -->
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/limsanky/">GitHub</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/sankarshana-v/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Sankarshana-img.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Sankarshana-img.JPG" class="hoverZoomLink"></a>
            </td>
            </td>
          </tr>
        
        
        
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Experience</heading>
              </td>
            </tr>
          </table>	
    
    
          <table width="100%" align="center" border="0" cellspacing="20" cellpadding="30">
            <!-- <tr>
              <td width="20%" valign="center">
                <img width = 50% id="microsoft_logo" src='images/microsoft_logo.png'>
                <div style="border:0px solid;height:30px;line-height:30px;" text-align: center></div>
                <p><font size=2 px color="#800000"> <a href="https://www.microsoft.com/zh-tw/abouttaiwan/twdc">Microsoft AI</a>  </font></p>
                <p><font size=2 px color="#800000" > [2022.04 - 2022.11]</font></p>
                <p><font size=2 px color="#000000" > Research Intern</font></p>

              </td>
              <td width="20%" valign="center">
                <img width = 77% id="intel_logo" src='images/intel_logo.png'>
                <div style="border:0px solid;height:30px;line-height:30px;" text-align: center></div>
                <p><font size=2 px color="#800000"> <a href="https://www.intel.com.tw/content/www/tw/zh/homepage.html">Intel</a>  </font></p>
                <p><font size=2 px color="#800000" > [2021.01 - 2021.08]</font></p>
                <p><font size=1 px color="#000000" > Hardware Verification Intern</font></p>

              </td>
              <td width="25%" valign="center">
                <img width = 33% id="deepq_logo" src='images/deepq_logo.jpg'>
                <div style="border:0px solid;height:2px;line-height:2px;" text-align: center></div>
                <p><font size=2 px color="#800000"> <a href="https://deepq.com/">DeepQ</a>  </font></p>
                <p><font size=2 px color="#800000" > [2020.07 - 2020.11]</font></p>
                <p><font size=2 px color="#000000" > Research Intern</font></p>

              </td>
            </tr> -->
    
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;text-align: left;">
              <heading>Research(* indicates equal contribution)</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            
        <tbody>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:5px;width:25%;vertical-align:middle">
                <img src='images/NAACL.png' width="180">
            </td>
            <td style="padding:5px;width:75%;vertical-align:middle">
              <a href="https://aclanthology.org/2022.findings-naacl.199/">
                <papertitle>AdapterBias: Parameter-efficient Token-dependent Representation Shift for Adapters in NLP Tasks</papertitle>
              </a>
              <br>
              <strong>Chin-Lun Fu<sup>*</sup></strong>,
              <a href="https://www.linkedin.com/in/zih-ching-chen-7158111b0/">Zih-Ching Chen<sup>*</sup></a>,
              <a href="https://www.facebook.com/profile.php?id=100002026928166">Yun-Ru Lee</a>, 
							<a href="https://speech.ee.ntu.edu.tw/~hylee/index.php">Hung-yi Lee</a>
              <br>
              <em>Findings-NAACL</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2205.00305">arXiv</a>
              /
              <a href="https://github.com/Allen0307/AdapterBias">code</a>
              <p></p>
              <p>
                In this work, we present AdapterBias. By adding token-dependent representation shifts to the PLM, AdapterBias shows competitive results even though it uses far fewer parameters than the existing methods.
              </p>
            </td>
          </tr>
					
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:5px;width:25%;vertical-align:middle">
                <img src='images/SLT.png' width="150">
            </td>
            <td style="padding:5px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.06175">
                <papertitle>Exploring Efficient-tuning Methods in Self-supervised Speech Models</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/zih-ching-chen-7158111b0/">Zih-Ching Chen<sup>*</sup></a>,
              <strong>Chin-Lun Fu<sup>*</sup></strong>,
              <a href="https://www.linkedin.com/in/chih-ying-liu-b7191922b/">Chih-Ying Liu</a>,
              <a href="https://swdanielli.github.io/">Shang-Wen (Daniel) Li</a>,
							<a href="https://speech.ee.ntu.edu.tw/~hylee/index.php">Hung-yi Lee</a>
              <br>
              <em>SLT</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2210.06175">arXiv</a>
              <!-- /
              <a href="https://github.com/Allen0307/AdapterBias">code</a> -->
              <p></p>
              <p>
                In this study, we aim to explore efficient tuning methods for speech self-supervised learning. We show that the performance parity can be achieved with over 90% parameter reduction, and discussed the pros and cons of efficient tuning techniques. This is the first comprehensive investigation of various adapter types across speech tasks.
              </p>
            </td>
          </tr>

          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:5px;width:25%;vertical-align:middle">
                <img src='images/ICME.png' width="180">
            </td>
            <td style="padding:5px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2208.07828">
                <papertitle>Learning Facial Liveness Representation for Domain Generalized Face Anti-spoofing</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/zih-ching-chen-7158111b0/">Zih-Ching Chen<sup>*</sup></a>,
              <a href="https://homerun-beauty.github.io/">Lin-Hsi Tsao<sup>*</sup></a>,
              <strong>Chin-Lun Fu<sup>*</sup></strong>,
              <a href="https://www.facebook.com/profile.php?id=100001525993985">Shang-Fu Chen</a>,
							<a href="http://vllab.ee.ntu.edu.tw/ycwang.html">Yu-Chiang Frank Wang</a>
              <br>
              <em>ICME</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2208.07828">arXiv</a>
              <!-- /
              <a href="https://github.com/Allen0307/AdapterBias">code</a> -->
              <p></p>
              <p>
                Based on the idea of representation disentanglement, we present a network architecture that is able to extract facial liveness, content, and domain features.
              </p>
            </td>
          </tr>

        </tbody></table> -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
              Source code credit to <a href="https://jonbarron.info/" target="_blank">Dr. Jon Barron</a></p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>